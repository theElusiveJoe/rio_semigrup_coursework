{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from functools import reduce\n",
    "from pprint import pp\n",
    "from typing import Callable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from algebra.graph.graph import Graph, MultipleType\n",
    "from algebra.monoid.controller import MonoidController\n",
    "from algos.graph_builder import military_algo\n",
    "from algos.graph_processor.hclasses_searcher import search_Hclasses\n",
    "from algos.graph_processor.idempotents_markupper import markup_idempotents\n",
    "from algos.isom_builder.eco.eco_algo import IsomBuilderEcoAlgo\n",
    "from algos.isom_builder.naive.naive_algo import IsomBuilderNaiveAlgo\n",
    "from algos.isom_builder.shared.algo_config import AlgoConfig\n",
    "from algos.isom_builder.shared.algo_init_set import AlgoInitSet\n",
    "from samples import funny_samples, random_sample, simple_samples\n",
    "from utils.events.eventsHandler import EH\n",
    "from utils.tester.tester import (FuncSet, NamedConfig, TestCase, comboStats,\n",
    "                                 inputType, inStats, intermediateType,\n",
    "                                 postStats, resultType, run_tests, sumStats)\n",
    "\n",
    "import sys \n",
    "sys.setrecursionlimit(9999999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test run functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timer(func: Callable[[postStats], resultType], args: postStats):\n",
    "    tstart = time.time()\n",
    "    res = func(args)\n",
    "    tfinish = time.time()\n",
    "    return tfinish-tstart, res\n",
    "\n",
    "\n",
    "def get_events():\n",
    "    return EH.process_events()\n",
    "\n",
    "\n",
    "def composer(args: tuple[float, dict[str, int | float]]):\n",
    "    d = args[1]\n",
    "    d['time'] = args[0]\n",
    "    print(d)\n",
    "    return d\n",
    "\n",
    "\n",
    "def sumUpper(stats_list: list[comboStats]):\n",
    "    res = dict()\n",
    "    for k in stats_list[0].keys(): # type: ignore\n",
    "        res[k] = list(map(lambda x: x[k], stats_list)) # type: ignore\n",
    "    return res\n",
    "\n",
    "\n",
    "def preparator(args: tuple[MonoidController, MonoidController, AlgoConfig]):\n",
    "    S1, S2, config = args\n",
    "    G1 = military_algo(S1)\n",
    "    G2 = military_algo(S2)\n",
    "    init_set = AlgoInitSet(S1=S1, S2=S2, G1=G1,\n",
    "                           G2=G2, config=config, H1=set(), H2=set())\n",
    "    return init_set\n",
    "\n",
    "\n",
    "def f(init_set: AlgoInitSet):\n",
    "\n",
    "    match init_set.config.use_eco_algo:\n",
    "        case True:\n",
    "            markup_idempotents(init_set.G1)\n",
    "            markup_idempotents(init_set.G2)\n",
    "            init_set.H1 = set(search_Hclasses(init_set.G1))\n",
    "            init_set.H2 = set(search_Hclasses(init_set.G2))\n",
    "\n",
    "            algo = IsomBuilderEcoAlgo(init_set)\n",
    "            result = algo.run()\n",
    "            return result\n",
    "\n",
    "        case False:\n",
    "            algo = IsomBuilderNaiveAlgo(init_set)\n",
    "            result = algo.run()\n",
    "            return result\n",
    "\n",
    "\n",
    "fs = FuncSet(\n",
    "    preparator=preparator,\n",
    "    f=f,\n",
    "    inProcessor=timer,\n",
    "    postProcessor=get_events,\n",
    "    statsComposer=composer,\n",
    "    sumUpper=sumUpper\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tests(name: str, A: int, B: int, generators: int):\n",
    "    Ski = []\n",
    "    while len(Ski) < 5:\n",
    "        S = random_sample.gen_random_group(\n",
    "            set_size=5, generators_num=generators, minimize=True)\n",
    "        if len(S.generators) != generators:\n",
    "            continue\n",
    "        g = military_algo(S)\n",
    "        print(len(g.nodes))\n",
    "        if len(g.nodes) > B or len(g.nodes) < A:\n",
    "            continue\n",
    "\n",
    "        print(S)\n",
    "        Ski.append(S)\n",
    "\n",
    "    Ski = sorted(Ski, key=len)\n",
    "    TestCases = [TestCase(name+\"_sg_\"+f'{i+1}', S.mixed())\n",
    "                 for i, S in enumerate(Ski)]\n",
    "    return TestCases\n",
    "\n",
    "\n",
    "def gen_tests2():\n",
    "    As = [200, 400, 600, 800]\n",
    "    Bs = [400, 600, 800, 1000]\n",
    "    geneartors = [2, 3, 4]\n",
    "    d = dict()\n",
    "\n",
    "    for A, B in zip(As, Bs):\n",
    "        d[(A, B)] = dict()\n",
    "        for gn in geneartors:\n",
    "            Ski = []\n",
    "            while len(Ski) < 5:\n",
    "                S = random_sample.gen_random_sample(\n",
    "                    set_size=random.randint(4, 5), generators_num=gn, minimize=True)\n",
    "                if len(S.generators) != gn:\n",
    "                    continue\n",
    "                g = military_algo(S)\n",
    "                if len(g.nodes) > B or len(g.nodes) < A:\n",
    "                    continue\n",
    "\n",
    "                Ski.append(TestCase(f'tt-{A}-{B}-{gn}-{len(Ski)+1}', S))\n",
    "\n",
    "            d[(A, B)][gn] = Ski\n",
    "    return d\n",
    "\n",
    "\n",
    "def gen_group(size: int, generators: int):\n",
    "    def fact(x): return 1 if x == 1 else x * fact(x-1)\n",
    "\n",
    "    while True:\n",
    "        S = random_sample.gen_random_group(\n",
    "            set_size=size,\n",
    "            generators_num=generators,\n",
    "            minimize=True)\n",
    "        if len(S.generators) != generators:\n",
    "            continue\n",
    "        g = military_algo(S)\n",
    "        print(len(g.nodes))\n",
    "        if len(g.nodes) != fact(size):\n",
    "            continue\n",
    "\n",
    "        return TestCase(f'S{size}_{generators}', S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tests(name):\n",
    "    with open(f'../output/{name}.pickle', 'rb') as f:\n",
    "        TestCases = pickle.load(f)\n",
    "    return TestCases\n",
    "\n",
    "\n",
    "def save_tests(name, res: list[TestCase]):\n",
    "    with open(f'../output/{name}.pickle', 'wb') as f:\n",
    "        pickle.dump(res, f)\n",
    "\n",
    "\n",
    "def load_result(name):\n",
    "    with open(f'../output/{name}_res.pickle', 'rb') as f:\n",
    "            res = pickle.load(f)\n",
    "    return res\n",
    "\n",
    "def save_result(name, res):\n",
    "    with open(f'../output/{name}_res.pickle', 'wb') as f:\n",
    "            pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1 = gen_tests('F1', 500, 1000, 3)\n",
    "# f2 = gen_tests('F2', 500, 1000, 4)\n",
    "# f3 = gen_tests('F3', 200, 300, 2)\n",
    "# f4 = gen_tests('F4', 70, 80, 3)\n",
    "\n",
    "# save_tests('f1', f1)\n",
    "# save_tests('f2', f2)\n",
    "# save_tests('f3', f3)\n",
    "# save_tests('f4', f4)\n",
    "\n",
    "# f1 = load_tests('f1')\n",
    "# f2 = load_tests('f2')\n",
    "# f3 = load_tests('f3')\n",
    "# f4 = load_tests('f4')\n",
    "\n",
    "# si = [gen_group(i, 2) for i in range(4, 6)] + [gen_group(i, 3) for i in range(4, 6)]\n",
    "# save_tests('Si', si)\n",
    "# si = load_tests('Si')\n",
    "\n",
    "from algebra.universe.transformations import Transformation\n",
    "\n",
    "\n",
    "cyc = [\n",
    "    TestCase('acyclic\\\\_500', MonoidController([Transformation([1] + list(range(1, 500)))])),\n",
    "    TestCase('acyclic\\\\_1000', MonoidController([Transformation([1] + list(range(1, 1000)))])),\n",
    "    TestCase('cyclic\\\\_500', MonoidController([Transformation([500] + list(range(1, 500)))])),\n",
    "    TestCase('cyclic\\\\_1000', MonoidController([Transformation([1000] + list(range(1, 1000)))])),\n",
    "]\n",
    "\n",
    "# tt = gen_tests2()\n",
    "# save_tests('tt', tt)\n",
    "tt = load_tests('tt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define configs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_eco = NamedConfig(\"std_eco\",\n",
    "                      AlgoConfig(\n",
    "                      ))\n",
    "\n",
    "monoid_mul = NamedConfig(\"monoid_mul\",\n",
    "                         AlgoConfig(\n",
    "                             second_chain_mult_type=MultipleType.monoid_multiply\n",
    "                         ))\n",
    "\n",
    "no_image = NamedConfig(\"no_image\",\n",
    "                       AlgoConfig(\n",
    "                           cache_isom_images_set=False,\n",
    "                           cache_isom_h_images_set=False,\n",
    "                           second_chain_mult_type=MultipleType.monoid_multiply\n",
    "                       ))\n",
    "\n",
    "no_chain = NamedConfig(\"no_chain\",\n",
    "                       AlgoConfig(\n",
    "                           cache_image_chains=False,\n",
    "                           second_chain_mult_type=MultipleType.monoid_multiply\n",
    "                       ))\n",
    "\n",
    "all_eco_configs = [\n",
    "    std_eco, monoid_mul, no_image, no_chain,\n",
    "\n",
    "]\n",
    "\n",
    "eco_vs_naive = [\n",
    "    monoid_mul,\n",
    "    NamedConfig(\"naive_mul\",\n",
    "                AlgoConfig(\n",
    "                    use_eco_algo=False,\n",
    "                    second_chain_mult_type=MultipleType.monoid_multiply,\n",
    "                )),\n",
    "    NamedConfig(\"naive_cay\",\n",
    "                AlgoConfig(\n",
    "                    use_eco_algo=False,\n",
    "                    second_chain_mult_type=MultipleType.graph_traverse,\n",
    "                )),\n",
    "]\n",
    "\n",
    "eco_vs_naive2 = [\n",
    "    monoid_mul,\n",
    "   NamedConfig(\"naive_mul\",\n",
    "                AlgoConfig(\n",
    "                    use_eco_algo=False,\n",
    "                    second_chain_mult_type=MultipleType.monoid_multiply,\n",
    "                )),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def go(name: str, tests: list[TestCase], configs: list[NamedConfig]):\n",
    "    res = run_tests(\n",
    "        tests,\n",
    "        configs,\n",
    "        fs,\n",
    "        1,\n",
    "    )\n",
    "\n",
    "    save_result(name, res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go('f1', f1, all_eco_configs)\n",
    "# go('f2', f2, all_eco_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go('f3', f3, eco_vs_naive)\n",
    "# go('f4', f4, eco_vs_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go('cyc', cyc, eco_vs_naive2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sizes = list(tt.keys())\n",
    "# gns = list(range(2,5))\n",
    "\n",
    "# df = pd.DataFrame(index=sizes, columns=gns)\n",
    "# print(df)\n",
    "# for s in sizes:\n",
    "#     for gn in gns:\n",
    "#         res = go('', tt[s][gn], [monoid_mul])\n",
    "#         times = []\n",
    "#         for v in res.values():\n",
    "#             for v2 in v.values():\n",
    "#                 times += v2['time']\n",
    "#         print(times)\n",
    "#         df.loc[str(s), gn] = sum(times)/len(times)\n",
    "#         df.to_csv('res.csv')\n",
    "#         print(df)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate result tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_table(res, tests, configs):\n",
    "    test_names = [tc.name for tc in tests[:2]]\n",
    "    config_names = [nc.name for nc in configs]\n",
    "    stats = list(res[test_names[0]][config_names[0]].keys())\n",
    "    cols = ['conf_name'] + stats\n",
    "\n",
    "    table = pd.DataFrame(columns=cols)\n",
    "\n",
    "    def sum_many_dicts(dicts):\n",
    "        def add_dicts(d1, d2): return dict(\n",
    "            [(k, d1[k]+d2[k]) for k in d1.keys()])\n",
    "        return reduce(\n",
    "            add_dicts, dicts[1:], dicts[0]\n",
    "        )\n",
    "\n",
    "    def mean(x):\n",
    "        d = {}\n",
    "        for k, v in x.items():\n",
    "            d[k] = sum(v)/len(v)\n",
    "        return d\n",
    "\n",
    "    gbc = dict(\n",
    "        (\n",
    "            f'\\\\raw{{{config_name.replace(\"_\", \"\\\\_\")}}}',\n",
    "            mean(sum_many_dicts(\n",
    "                list(map(lambda x: x[config_name], res.values()))))\n",
    "        )\n",
    "        for config_name in config_names\n",
    "    )\n",
    "\n",
    "    for k1 in gbc.keys():\n",
    "        for k2, v in gbc[k1].items():\n",
    "            match k2:\n",
    "                case 'time':\n",
    "                    gbc[k1][k2] = (\n",
    "                        \"{:.2f}\".format(v)\n",
    "                    )\n",
    "                case _:\n",
    "                    gbc[k1][k2] = (\n",
    "                        str(int(v))\n",
    "                    )\n",
    "\n",
    "    table = pd.DataFrame.from_dict(gbc).transpose()\n",
    "\n",
    "    print('\\\\hline\\n'.join(table.to_latex().split('\\n')[4:-3]) + '\\\\hline')\n",
    "    return table\n",
    "\n",
    "def results_to_table2(res, tests, configs):\n",
    "\n",
    "    table = pd.DataFrame(columns = ['test', 'config', 'checks', 'mults', 'time'])\n",
    "    def mean(x):\n",
    "        d = {}\n",
    "        for k, v in x.items():\n",
    "            d[k] = sum(v)/len(v)\n",
    "        return d\n",
    "    \n",
    "    for test_name, configs in res.items():\n",
    "        for config_name, result in configs.items():\n",
    "            row = [test_name, config_name] \n",
    "            for k2, v in result.items():\n",
    "                v = sum(v)/len(v)\n",
    "                match k2:\n",
    "                    case 'time':\n",
    "                        row.append(\n",
    "                            \"{:.2f}\".format(v)\n",
    "                        )\n",
    "                    case _:\n",
    "                        row.append(\n",
    "                            str(int(v))\n",
    "                        )\n",
    "            table.loc[len(table)] = row\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    print('\\\\hline\\n'.join(table.to_latex(index=False).split('\\n')[4:-3]) + '\\\\hline')\n",
    "    return table\n",
    "\n",
    "def results_to_table3(res, tests, configs):\n",
    "\n",
    "    table = pd.DataFrame(columns = ['test', 'config', 'checks', 'mults', 'time'])\n",
    "    def mean(x):\n",
    "        d = {}\n",
    "        for k, v in x.items():\n",
    "            d[k] = sum(v)/len(v)\n",
    "        return d\n",
    "    \n",
    "    for test_name, configs in res.items():\n",
    "        for config_name, result in configs.items():\n",
    "            row = [test_name, config_name] \n",
    "            for k2, v in result.items():\n",
    "                v = sum(v)/len(v)\n",
    "                match k2:\n",
    "                    case 'time':\n",
    "                        row.append(\n",
    "                            \"{:.2f}\".format(v)\n",
    "                        )\n",
    "                    case _:\n",
    "                        row.append(\n",
    "                            str(int(v))\n",
    "                        )\n",
    "            table.loc[len(table)] = row\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    print('\\\\hline\\n'.join(table.to_latex(index=False).split('\\n')[4:-3]) + '\\\\hline')\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_tests(TestCases: list[TestCase], name):\n",
    "    table = pd.DataFrame(\n",
    "        columns=['Семейство', 'порождающие элементы', 'кол-во элементов', 'кол-во $\\\\gh$--классов'])\n",
    "\n",
    "    for i, test_case in enumerate(TestCases):\n",
    "        g = military_algo(test_case.S)\n",
    "        hclasses = search_Hclasses(g)\n",
    "        hclasses_sizes = dict()\n",
    "        for hclass in hclasses:\n",
    "            s = len(hclass.elems)\n",
    "            if s in hclasses_sizes:\n",
    "                hclasses_sizes[s] += 1\n",
    "            else:\n",
    "                hclasses_sizes[s] = 1\n",
    "\n",
    "        row = [\n",
    "            f\"$F_{i//5+1}$\",\n",
    "            '\\\\makecell{$' + str(test_case.S.generators).replace('), ',\n",
    "                                                                 ')$, $').replace('[', '').replace(']', '') + '$}',\n",
    "            len(g.nodes),\n",
    "            len(hclasses)]\n",
    "        table.loc[i] = row\n",
    "\n",
    "    # table = table.sort_values(\"кол-во элементов\")\n",
    "    pp(table)\n",
    "    res = table.to_latex(index=False)\n",
    "    res = res.replace('\\n', '\\\\hline \\n')\n",
    "    print(res)\n",
    "    with open(f'../output/{name}_tests.tex', 'w') as f:\n",
    "        f.write(res)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_to_table2(load_result('cyc'), cyc, eco_vs_naive2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_tests(load_tests('f3'), 'f3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
